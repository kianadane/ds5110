{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11f5720-077b-4c4e-8acf-8ab1ac5c5386",
   "metadata": {},
   "source": [
    "# Basic Python multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6720552-4f45-4e14-ae12-258a3c3e8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55324ed2-d070-4920-80d1-17e69571383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 5\n",
      "0.10054564476013184 seconds\n"
     ]
    }
   ],
   "source": [
    "def add(xy):\n",
    "    sleep(0.1) # imagine this is some complicated, slow calculation\n",
    "    return xy[0] + xy[1]\n",
    "\n",
    "t0 = time()\n",
    "print(\"result:\", add((2,3)))\n",
    "t1 = time()\n",
    "print(t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c064cfe-768f-4b6e-92c6-1cb200600acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 11\n",
      "result: 12\n",
      "result: 13\n",
      "result: 14\n",
      "result: 15\n",
      "result: 16\n",
      "result: 17\n",
      "result: 18\n",
      "result: 19\n",
      "result: 20\n",
      "1.0040993690490723 seconds\n"
     ]
    }
   ],
   "source": [
    "xy_pairs = [(10,1),(10,2),(10,3),(10,4),(10,5),(10,6),(10,7),(10,8),(10,9),(10,10)]\n",
    "\n",
    "t0 = time()\n",
    "for xy in xy_pairs:\n",
    "    print(\"result:\", add(xy))\n",
    "t1 = time()\n",
    "print(t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd519713-fec2-48ff-83b7-c073937ef11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1bbe01-3bff-4d2c-a91a-c4ac24a06f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 11\n",
      "result: 12\n",
      "result: 13\n",
      "result: 14\n",
      "result: 15\n",
      "result: 16\n",
      "result: 17\n",
      "result: 18\n",
      "result: 19\n",
      "result: 20\n",
      "0.10954976081848145 seconds\n"
     ]
    }
   ],
   "source": [
    "with Pool(10) as p:\n",
    "    t0 = time()\n",
    "    for result in p.map(add, xy_pairs):\n",
    "        print(\"result:\", result)\n",
    "    t1 = time()\n",
    "    print(t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64927e-015b-4c23-b55e-3a7dbf1ad8b3",
   "metadata": {},
   "source": [
    "We can see some good speedups from the above examples. That's because the function mostly does sleep and you can pack many \"sleep\" functions with very limited CPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d399e24-65b2-4e0b-8326-c3307e2d4e45",
   "metadata": {},
   "source": [
    "# Python processing with some compute-intensive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610e5e82-a891-4cfa-9b1d-f0b82547d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 11\n",
      "result: 12\n",
      "result: 13\n",
      "result: 14\n",
      "result: 15\n",
      "result: 16\n",
      "result: 17\n",
      "result: 18\n",
      "result: 19\n",
      "result: 20\n",
      "0.8569386005401611 seconds (1 process)\n"
     ]
    }
   ],
   "source": [
    "def add_compute(xy):\n",
    "    for i in range(3000000): # loop 3 million times\n",
    "        pass\n",
    "    return xy[0] + xy[1]\n",
    "\n",
    "with Pool(1) as p:\n",
    "    t0 = time()\n",
    "    for result in p.map(add_compute, xy_pairs):\n",
    "        print(\"result:\", result)\n",
    "    t1 = time()\n",
    "    print(t1 - t0, \"seconds (1 process)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a452a7f2-fe73-45bf-a635-ad2ebc766db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 11\n",
      "result: 12\n",
      "result: 13\n",
      "result: 14\n",
      "result: 15\n",
      "result: 16\n",
      "result: 17\n",
      "result: 18\n",
      "result: 19\n",
      "result: 20\n",
      "0.9076948165893555 seconds (10 processes)\n"
     ]
    }
   ],
   "source": [
    "with Pool(10) as p:\n",
    "    t0 = time()\n",
    "    for result in p.map(add_compute, xy_pairs):\n",
    "        print(\"result:\", result)\n",
    "    t1 = time()\n",
    "    print(t1 - t0, \"seconds (10 processes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e361eb4-6156-4cae-bfa3-b94d9e60662f",
   "metadata": {},
   "source": [
    "For compute-intensive tasks, the \"speedup\" I can achieve is really bounded by the number of CPU cores I have on that computer, no matter how many processes I actually launched (in the above example, 10 processes). \n",
    "\n",
    "In this case, it's a bit tricky to guess how many CPU cores I have on my EC2 VM, as I did not observe a good speedup by parallelizing ten tasks over 10 processes. The reason why might be due to the weak CPU power of the t3.large EC2 VM that I am using. \n",
    "\n",
    "I also ran the same test on my local computer, a 10-core MacBook, and we saw good speedups. See the other notebook for detailed result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4b9a2-9e60-461c-b997-4801713e12e5",
   "metadata": {},
   "source": [
    "# Python thread-level parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1d2b09-cce9-47cf-8916-e32c8733d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c2b1e3-1d40-400d-812a-8b463b179398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_bound_task():\n",
    "    for i in range(3000000):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc191ab2-914e-477b-a468-a3c4273a60ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1160440444946289 seconds (1 single python thread)\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "t0 = time()\n",
    "for _ in range(1):\n",
    "    thread = threading.Thread(target=cpu_bound_task)\n",
    "    thread.start()\n",
    "    threads.append(thread) # insert created thread object into the list\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join() # parent thread waits for child thread(s) to complete and join\n",
    "\n",
    "t1 = time()\n",
    "print(t1 - t0, \"seconds (1 single python thread)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9543a2a9-8f33-4515-babb-d702236c3e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9581670761108398 seconds (10 single python thread)\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "t0 = time()\n",
    "for _ in range(10):\n",
    "    thread = threading.Thread(target=cpu_bound_task)\n",
    "    thread.start()\n",
    "    threads.append(thread) # insert created thread object into the list\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join() # parent thread waits for child thread(s) to complete and join\n",
    "\n",
    "t1 = time()\n",
    "print(t1 - t0, \"seconds (10 single python thread)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c37cf4-9421-483c-98a1-8c3c654df5fd",
   "metadata": {},
   "source": [
    "Python threads are not able to achieve parallelism, due to the constraint of GIL (global interpreter lock). That explains why the run with 10 threads led to almost 10X of execution time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d36e75-55ec-4710-b6df-8c1836403cf3",
   "metadata": {},
   "source": [
    "# Global variable in Python threads vs. Python processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd60c7bc-6f89-4e7e-ad9a-136f7558e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "def increment(amount):\n",
    "    global total\n",
    "    total += amount\n",
    "    print(f\"sub total so far: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca4439ee-164a-4869-9daf-9a00c6dd1384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub total so far: 5\n",
      "sub total so far: 10\n",
      "sub total so far: 15\n",
      "sub total so far: 20\n",
      "sub total so far: 25\n",
      "sub total so far: 30\n",
      "sub total so far: 35\n",
      "sub total so far: 40\n",
      "Final result: 40\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "for _ in range(8):\n",
    "    thread = threading.Thread(target=increment, args=(5,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join() \n",
    "\n",
    "print(\"Final result:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83bf1c-f5b8-4e56-b402-0de6078a20b9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Python threads share the virtual memory address space, therefore different threads created within the same process see the same copy of global variable 'total'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68aa1184-e3c5-46ba-9a43-769d968b3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45fd697-db47-4289-9d19-f1bd3be143bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4364: sub total so far: 5\n",
      "4365: sub total so far: 5\n",
      "\n",
      "\n",
      "4364: sub total so far: 10\n",
      "4365: sub total so far: 10\n",
      "\n",
      "\n",
      "4364: sub total so far: 15\n",
      "4365: sub total so far: 15\n",
      "\n",
      "\n",
      "4364: sub total so far: 20\n",
      "\n",
      "4365: sub total so far: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "def increment(amount):\n",
    "    pid = os.getpid() # get the process identifier\n",
    "    global total\n",
    "    total += amount\n",
    "    print(f\"{pid}: sub total so far: {total}\\n\")\n",
    "\n",
    "with Pool(2) as p:\n",
    "    p.map(increment, [5,5,5,5,5,5,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d3dd15f-b84a-458d-bf2b-97be8f71a29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550139a-3931-489d-bb25-3f038823fd9d",
   "metadata": {},
   "source": [
    "However, in the case of multi-process parallelism, things become a bit complicated. Child processes created from a parent process also create a separate copy of the global variable 'total' in their own virtual memory address space. Each child process will then work on its own copy of 'total'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
